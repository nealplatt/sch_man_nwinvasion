{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T20:24:41.786828Z",
     "start_time": "2020-11-23T20:24:41.274144Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import vcf\n",
    "import re\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import pysam\n",
    "import pybedtools\n",
    "import subprocess\n",
    "import numpy as np\n",
    "\n",
    "from IPython.display import Image\n",
    "from Bio import SeqIO\n",
    "\n",
    "\n",
    "## import rpy2.ipython\n",
    "\n",
    "\n",
    "## %load_ext rpy2.ipython\n",
    "\n",
    "os.chdir(\"/master/nplatt/sch_man_nwinvasion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Descriptive Stats\n",
    "\n",
    "Calculate basic descriptive stats including read count, sample coverage, probe depth etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T20:36:21.444617Z",
     "start_time": "2020-11-23T20:36:20.839149Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/master/nplatt/miniconda3/envs/sch_man_nwinvasion-jupyter/lib/python3.8/subprocess.py:849: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stderr = io.open(errread, 'rb', bufsize)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BedTool(results/probe_coverage_and_read_counts/merged_probes.bed)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get merged probes\n",
    "probe_bed = pybedtools.BedTool(\"data/renamed-sma_agilent_baits.v7.0.chr_reorderd.bed\")\n",
    "merged_probe_bed = probe_bed.merge(d=0)\n",
    "\n",
    "merged_probe_bed.saveas('results/probe_coverage_and_read_counts/merged_probes.bed')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-23T21:10:50.396819Z",
     "start_time": "2020-11-23T21:10:50.365187Z"
    }
   },
   "outputs": [],
   "source": [
    "#read vcf to get all samples and store based on genome or exome\n",
    "vcf_reader = vcf.Reader(open('results/variant_filtration/smv7_ex_snps.vcf', 'r'))\n",
    "\n",
    "samples={}\n",
    "samples['genome'] = [x for x in vcf_reader.samples if re.search(\"^ER\", x)]     \n",
    "samples['exome'] = [x for x in vcf_reader.samples if not re.search(\"^ER\", x)]     \n",
    "\n",
    "#create empty df to store info\n",
    "df = pd.DataFrame(index=[samples['exome'] + samples['genome']])\n",
    "\n",
    "#fxn to count num seqs in fastq.gz file\n",
    "def num_seqs(in_fastq_gz):\n",
    "    n=0\n",
    "    with gzip.open(in_fastq_gz, \"rt\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fastq\"):\n",
    "            n=n+1\n",
    "    return n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-11-23T21:14:50.621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 of 156\n",
      "2 of 156\n",
      "3 of 156\n",
      "4 of 156\n",
      "5 of 156\n",
      "6 of 156\n",
      "7 of 156\n",
      "8 of 156\n",
      "9 of 156\n"
     ]
    }
   ],
   "source": [
    "#get all read count info\n",
    "merged_probes_bed = 'results/probe_coverage_and_read_counts/merged_probes.bed'\n",
    "\n",
    "num_raws  = []\n",
    "num_filts = []\n",
    "num_maps  = []\n",
    "seq_types = []\n",
    "avgs_covs       = []\n",
    "perc_cov_gt_10s = []\n",
    "perc_cov_lt_1s  = []\n",
    "\n",
    "#count num of raw and filtered reads\n",
    "i=0\n",
    "for sample in samples['exome'] + samples['genome']:\n",
    "    i+=1\n",
    "    print(\"{} of {}\".format(i, len(df)))\n",
    "    seq_type = \"\"\n",
    "    \n",
    "    if sample in samples['exome']:\n",
    "        raw_file = \"data/exomes/{}_R1.fastq.gz\".format(sample)\n",
    "        seq_type = \"exome\"\n",
    "    if sample in samples['genome']:\n",
    "        raw_file = \"data/sra/{}_1.fastq.gz\".format(sample)\n",
    "        seq_type = \"genome\"\n",
    "        \n",
    "    #raw reads\n",
    "    num_raw = num_seqs(raw_file)\n",
    "    \n",
    "    #num mapped reads\n",
    "    bam_file = pysam.AlignmentFile(\"results/mapped_reads/{}_processed.bam\".format(sample), \"rb\")\n",
    "    num_map = samfile.mapped\n",
    "\n",
    "    #get coverage\n",
    "    bam_file = \"results/mapped_reads/{}_processed.bam\".format(sample)\n",
    "    out_prfx = \"results/probe_coverage_and_read_counts/mosdepth/{}\".format(sample)\n",
    "    \n",
    "    mos_cmd = \"mosdepth -t 4 --by {} {} --no-per-base {}\".format(merged_probes_bed, out_prfx, bam_file)\n",
    "    mos_cmd=mos_cmd.split(\" \")\n",
    "\n",
    "    #run mosdepth\n",
    "    process = subprocess.run(mos_cmd, \n",
    "                         stdout=subprocess.PIPE, \n",
    "                         universal_newlines=True)\n",
    "\n",
    "    #calculate cov stats\n",
    "    covs=np.array([])\n",
    "    with gzip.open(\"results/probe_coverage_and_read_counts/mosdepth/{}.regions.bed.gz\".format(sample), 'rb') as mos_infile:\n",
    "        for cov_entry in mos_infile:\n",
    "            chrom, start, stop, cov = cov_entry.decode(\"utf-8\") .rstrip().split(\"\\t\") \n",
    "            cov=float(cov)\n",
    "            covs=np.append(covs, cov)\n",
    "        \n",
    "    avg_cov = np.mean(covs)\n",
    "    perc_cov_gt_10 = np.sum(covs>10)/len(covs)\n",
    "    perc_cov_lt_1 = np.sum(covs<1)/len(covs)\n",
    "    \n",
    "    #build arrays for df import\n",
    "    seq_types.append(seq_type)\n",
    "    num_raws.append(num_raw)\n",
    "    num_maps.append(num_map)\n",
    "    avgs_covs.append(avg_cov)\n",
    "    perc_cov_gt_10s.append(perc_cov_gt_10)\n",
    "    perc_cov_lt_1s.append(perc_cov_lt_1)\n",
    "\n",
    "df.insert(0,'seq_type', seq_types)\n",
    "df.insert(1,'num_raw', num_raws)\n",
    "df.insert(2,'mapped_reads', num_maps)\n",
    "df.insert(3,'avg_probe_cov', avgs_covs)\n",
    "df.insert(4,'perc_probes_gt10x', perc_cov_gt_10s)\n",
    "df.insert(5,'perc_probes_failed', perc_cov_lt_1s)\n",
    "\n",
    "csv_file = \"results/probe_coverage_and_read_counts/samples_stats.csv\"\n",
    "df.to_csv(csv_file, index=False, header=True, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get an idea of the number of genotyped sites\n",
    "\n",
    "# #gt rate at all gtd sites\n",
    "# MISSING_ALL=$(grep $SAMPLE results/variant_filtration/indiv_gt_rate.tbl | cut -f5)\n",
    "\n",
    "# #gt rate at filtered sites\n",
    "# MISSING_FILT=$(grep $SAMPLE results/variant_filtration/gt_rate_per_indiv_at_filtered_sites.tbl | cut -f5)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
