{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T21:00:55.199310Z",
     "start_time": "2020-11-18T21:00:53.506046Z"
    }
   },
   "outputs": [],
   "source": [
    "#run in sch_man_nwinvasion-jupyter environment\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import allel\n",
    "import math\n",
    "import yaml\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "#from scipy import stats\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T21:00:55.205604Z",
     "start_time": "2020-11-18T21:00:55.202276Z"
    }
   },
   "outputs": [],
   "source": [
    "os.chdir(\"/master/nplatt/sch_man_nwinvasion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T18:05:57.753151Z",
     "start_time": "2020-11-18T18:05:57.747522Z"
    }
   },
   "source": [
    " Get population assignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T21:01:22.819000Z",
     "start_time": "2020-11-18T21:01:22.778847Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('data/pop_assign.yml') as yaml_file:\n",
    "    pop_assign = yaml.load(yaml_file, Loader=yaml.FullLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read in the vcf file and get pop specific allele counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T21:01:47.679452Z",
     "start_time": "2020-11-18T21:01:24.217382Z"
    }
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "# get genotype info per population\n",
    "\n",
    "#read in vcf\n",
    "filtered_callset=allel.read_vcf('results/variant_filtration/smv7_ex_autosomes.vcf')\n",
    "\n",
    "#now get an index for each sample/population\n",
    "samples = filtered_callset[\"samples\"]\n",
    "\n",
    "i=0\n",
    "pop_idxs = defaultdict(list)   \n",
    "for sample in samples:  \n",
    "    pop_idxs[pop_assign[sample]].append(i) \n",
    "    i=i+1\n",
    "\n",
    "pops= list(pop_idxs.keys()) \n",
    "\n",
    "#get genotypes\n",
    "gt=allel.GenotypeArray(filtered_callset['calldata/GT'])\n",
    "\n",
    "#now get allele count per population\n",
    "ac=gt.count_alleles()\n",
    "\n",
    "pop_ac={}\n",
    "for pop in pops:\n",
    "    pop_ac[pop] = gt.count_alleles(subpop=pop_idxs[pop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all of the accessible bases (since used probes) and get an idea of the length of each chr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T21:01:52.479164Z",
     "start_time": "2020-11-18T21:01:47.682196Z"
    }
   },
   "outputs": [],
   "source": [
    "#initialize an list the lenght of each contig to fale\n",
    "accessible_bases = {}\n",
    "chrom_length = {}\n",
    "\n",
    "with open('data/genomes/Smansoni_v7.fa.fai', 'r') as fai:\n",
    "    for entry in fai:\n",
    "        chrom, length, *offset = entry.rstrip().split(\"\\t\")\n",
    "        chrom_length[chrom] = int(length)\n",
    "        accessible_bases[chrom]=[False] * int(length)\n",
    "\n",
    "\n",
    "#now read the bed\n",
    "with open('data/renamed-sma_agilent_baits.v7.0.chr_reorderd.bed', 'r') as in_bed_file:\n",
    "    for bed_entry in in_bed_file:\n",
    "        chrom, start, stop = bed_entry.rstrip().split(\"\\t\")\n",
    "        for base in range(int(start) - 1, int(stop)):\n",
    "             accessible_bases[chrom][base]=True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pi, Tajima's D, Theta, Ne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T21:27:42.906614Z",
     "start_time": "2020-11-18T21:24:01.940752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rodhaini:0.000482784736658036\t0.4786576179515533\t0.0004285068495203049\t13225.520046922991\n",
      "brazil:0.0006229634190808082\t0.22480080261256646\t0.0005842378015352539\t18032.03091158191\n",
      "niger:0.0005282391905747682\t-0.5633207858097302\t0.000607062748979703\t18736.50459813898\n",
      "senegal:0.000452726735843687\t-1.4171249923020972\t0.0007125456426101054\t21992.149463274858\n",
      "tanzania:0.0013144180653959314\t-0.7287596992860278\t0.0016688696510230978\t51508.32256244129\n"
     ]
    }
   ],
   "source": [
    "for pop in [\"rodhaini\", \"brazil\", \"niger\", \"senegal\", \"tanzania\"]:\n",
    "    accessible_genome_size = 0\n",
    "    pi_s=[]\n",
    "    td_s=[]\n",
    "    theta_s=[]\n",
    "    mu=8.1e-9\n",
    "\n",
    "    #now loop through each chromosome\n",
    "    for chrom in list(set(filtered_callset['variants/CHROM'])) :\n",
    "        target_sites = filtered_callset['variants/CHROM'] == chrom\n",
    "\n",
    "     \n",
    "        chr_poss = filtered_callset['variants/POS'][target_sites]\n",
    "        chr_acs  = pop_ac[pop][target_sites]\n",
    "        chr_len  = len(accessible_bases[chrom])\n",
    "        \n",
    "\n",
    "        chr_pi    = allel.sequence_diversity(chr_poss, chr_acs, start=1, stop=chr_len, is_accessible=accessible_bases[chrom])\n",
    "        chr_theta = allel.watterson_theta(chr_poss, chr_acs, is_accessible=accessible_bases[chrom])\n",
    "        chr_td    = allel.tajima_d(chr_acs, pos=chr_poss, start=1, stop=chr_len, min_sites=3)\n",
    "\n",
    "\n",
    "        num_accessible_bases = sum(accessible_bases[chrom])\n",
    "        theta_s += [chr_theta] * num_accessible_bases\n",
    "        pi_s    += [chr_pi]    * num_accessible_bases\n",
    "        td_s    += [chr_td]    * num_accessible_bases\n",
    "\n",
    "        accessible_genome_size += num_accessible_bases\n",
    "\n",
    "    pi    = np.mean(pi_s)\n",
    "    td    = np.mean(td_s)\n",
    "    theta = np.mean(theta_s)\n",
    "    ne = theta/(4 * mu)\n",
    "\n",
    "    outline=\"{}:{}\\t{}\\t{}\\t{}\".format(pop, pi, td, theta, ne)\n",
    "    print(outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## genome-wide Fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T18:20:53.134311Z",
     "start_time": "2020-11-18T18:20:09.982947Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pop1\tpop2\tfst\tSE\n",
      "niger\ttanzania\t0.3478709508995357\t0.0031245927121814343\n",
      "niger\tbrazil\t0.15190265241779138\t0.0036320702629908355\n",
      "niger\trodhaini\t0.9305794094480899\t0.0011327164324128835\n",
      "niger\tsenegal\t0.13546469500849986\t0.0042380948004846425\n",
      "tanzania\tbrazil\t0.3790452130775332\t0.0034260999716080004\n",
      "tanzania\trodhaini\t0.8439788473873892\t0.001616842545372161\n",
      "tanzania\tsenegal\t0.41553169413628227\t0.00321957992128926\n",
      "brazil\trodhaini\t0.9189907169217962\t0.001343597256193136\n",
      "brazil\tsenegal\t0.23465523710207586\t0.0046503734975993725\n",
      "rodhaini\tsenegal\t0.9370016347766583\t0.001296004539097002\n"
     ]
    }
   ],
   "source": [
    "print(\"pop1\\tpop2\\tfst\\tSE\")\n",
    "pops=[\"niger\", \"tanzania\", \"brazil\", \"rodhaini\", \"senegal\"]\n",
    "\n",
    "pop_combs=list(itertools.combinations(pops, 2)) \n",
    "\n",
    "for comb in pop_combs:\n",
    "    pop1=comb[0]\n",
    "    pop2=comb[1]\n",
    "    \n",
    "    idxs=[pop_idxs[pop1], pop_idxs[pop2]]\n",
    "    \n",
    "    #allel.average_weir_cockerham_fst(g, subpops, blen, max_allele=None)\n",
    "    fst, se, block_fsts, jacknife_fsts = allel.average_weir_cockerham_fst(gt, idxs, 100)\n",
    "    \n",
    "    outline=\"{}\\t{}\\t{}\\t{}\".format(pop1, pop2, fst, se)\n",
    "    print(outline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-18T18:08:22.615957Z",
     "start_time": "2020-11-18T18:08:22.612803Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "## sliding window Fst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "os.chdir(\"/master/nplatt/sch_man_nwinvasion\")\n",
    "\n",
    "if not os.path.exists(\"results/fst_per_window\"):\n",
    "    os.mkdir(\"results/fst_per_window\")\n",
    "    \n",
    "with open('data/pop_assign.yml') as yaml_file:\n",
    "    pop_assign = yaml.load(yaml_file, Loader=yaml.FullLoader)\n",
    "\n",
    "#-----------------------------------\n",
    "# get lengths from cumul positions\n",
    "#make sure that all stops are not gt chrom length\n",
    "chr_length = {}\n",
    "#genome_size = 0\n",
    "with open('/master/nplatt/sch_man_nwinvasion/data/genomes/Smansoni_v7.fa.fai', 'r') as fai:\n",
    "    for entry in fai:\n",
    "        chrom, length, *offset = entry.rstrip().split(\"\\t\")\n",
    "        chr_length[chrom]=int(length)\n",
    "\n",
    "    cumul_start={}\n",
    "    cumul_start['SM_V7_1']=0\n",
    "    cumul_start['SM_V7_2']= cumul_start['SM_V7_1'] + chr_length['SM_V7_1']\n",
    "    cumul_start['SM_V7_3']= cumul_start['SM_V7_2'] + chr_length['SM_V7_2']\n",
    "    cumul_start['SM_V7_4']= cumul_start['SM_V7_3'] + chr_length['SM_V7_3']\n",
    "    cumul_start['SM_V7_5']= cumul_start['SM_V7_4'] + chr_length['SM_V7_4']\n",
    "    cumul_start['SM_V7_6']= cumul_start['SM_V7_5'] + chr_length['SM_V7_5']\n",
    "    cumul_start['SM_V7_7']= cumul_start['SM_V7_6'] + chr_length['SM_V7_6']\n",
    "    scanned_size = cumul_start['SM_V7_7'] + chr_length['SM_V7_7']\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# get genotype info per population\n",
    "\n",
    "#read in vcf\n",
    "callset=allel.read_vcf('results/variant_filtration/smv7_ex_autosomes.vcf')\n",
    "\n",
    "#now get an index for each sample/population\n",
    "samples = callset[\"samples\"]\n",
    "\n",
    "i=0 \n",
    "pop_idxs = defaultdict(list)   \n",
    "for sample in samples:  \n",
    "     pop_idxs[pop_assign[sample]].append(i) \n",
    "     i=i+1 \n",
    "\n",
    "pops= list(pop_idxs.keys()) \n",
    "\n",
    "#get genotypes\n",
    "gt=allel.GenotypeArray(callset['calldata/GT'])\n",
    "\n",
    "#now get allele count per population\n",
    "ac=gt.count_alleles()\n",
    "\n",
    "#for simplicity add maf info to callset data\n",
    "maf=ac[:, :2].min(axis=1)/ac[:, :2].sum(axis=1)\n",
    "callset['maf']=maf \n",
    "\n",
    "pop_ac={}\n",
    "for pop in pops:\n",
    "    pop_ac[pop] = gt.count_alleles(subpop=pop_idxs[pop])\n",
    "    \n",
    "#-------------------------------------------------------------------------------\n",
    "#generate windows\n",
    "window=100_000\n",
    "\n",
    "#define an array of window start and stops\n",
    "window_starts = [int(x - (window/2)) for x in callset['variants/POS']]\n",
    "window_stops  = [int(x + (window/2)) for x in callset['variants/POS']]\n",
    "\n",
    "#make sure that window starts are all gt 1\n",
    "window_starts = [1 if i < 1 else i for i in window_starts]\n",
    "\n",
    "\n",
    "#make sure that all stops are not gt chrom length\n",
    "chr_length = {}\n",
    "#genome_size = 0\n",
    "with open('/master/nplatt/sch_man_nwinvasion/data/genomes/Smansoni_v7.fa.fai', 'r') as fai:\n",
    "    for entry in fai:\n",
    "        chrom, length, *offset = entry.rstrip().split(\"\\t\")\n",
    "        chr_length[chrom]=int(length)\n",
    "        #genome_size = genome_size + chr_length[chrom]\n",
    "    \n",
    "i=0\n",
    "for stop in window_stops:\n",
    "    chrom = callset['variants/CHROM'][i]\n",
    "    \n",
    "    if stop > chr_length[chrom]:\n",
    "        window_stops[i]=chr_length[chrom]\n",
    "    i=i+1\n",
    "    \n",
    "windows = np.column_stack((np.array(window_starts), \n",
    "                           np.array(window_stops)))\n",
    "\n",
    "callset['windows']=windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "# fst calculations\n",
    "\n",
    "pops = [\"brazil\", \"tanzania\", \"niger\", \"senegal\" ]\n",
    "\n",
    "idx_comps = {\"brazil\":   [pop_idxs[\"brazil\"],   pop_idxs[\"tanzania\"] + pop_idxs[\"niger\"]  + pop_idxs[\"senegal\"] ],\n",
    "             \"tanzania\": [pop_idxs[\"tanzania\"], pop_idxs[\"brazil\"]   + pop_idxs[\"niger\"]  + pop_idxs[\"senegal\"] ],\n",
    "             \"niger\":    [pop_idxs[\"niger\"],    pop_idxs[\"tanzania\"] + pop_idxs[\"brazil\"] + pop_idxs[\"senegal\"] ],\n",
    "             \"senegal\":  [pop_idxs[\"senegal\"],  pop_idxs[\"tanzania\"] + pop_idxs[\"niger\"]  + pop_idxs[\"brazil\"] ]}\n",
    "\n",
    "#make comparisons between population\n",
    "for pop in idx_comps.keys():\n",
    "    print(pop)\n",
    "    pop1_idx = idx_comps[pop][0]\n",
    "    pop2_idx = idx_comps[pop][1]\n",
    "\n",
    "    fst_s             = []\n",
    "    fst_calc_window_s = []\n",
    "    fst_count_s       = []\n",
    "\n",
    "    #create empty dataframe to store data    \n",
    "    headers = [\"chrom\", \"pos\", \"fst\", \"smoothed_fst\", \"window\", \"num_snps\", \"zscore\", \"pvalue\", \"-log10(p)\"]\n",
    "    df=pd.DataFrame(columns=headers) \n",
    "\n",
    "    #now loop through each chromosome\n",
    "    for chrom in list(set(callset['variants/CHROM'])) :\n",
    "        target_sites = np.logical_and( callset['maf'] < 0.05, \n",
    "                                       callset['variants/CHROM'] == chrom )  \n",
    "\n",
    "        chr_gts  = gt[target_sites]\n",
    "        chr_poss = callset['variants/POS'][target_sites]\n",
    "        chr_wins = callset['windows'][target_sites]\n",
    "\n",
    "        \n",
    "        fsts, fst_calc_windows, fst_counts =allel.windowed_weir_cockerham_fst(chr_poss, chr_gts, subpops=[pop1_idx, pop2_idx], windows=chr_wins )\n",
    "\n",
    "        #get rid of nan values\n",
    "        useful_values = np.logical_and( np.isfinite(fsts), fst_counts>=10) \n",
    "\n",
    "        fsts = fsts[useful_values]\n",
    "        fst_calc_windows = fst_calc_windows[useful_values]\n",
    "        fst_counts = fst_counts[useful_values]\n",
    "        chr_poss = chr_poss[useful_values]\n",
    "\n",
    "        #set negative fst values to 0\n",
    "        i=0\n",
    "        for fst in fsts:\n",
    "            if fst <0:\n",
    "                fsts[i]=0\n",
    "            i=i+1        \n",
    "        \n",
    "        #smooth\n",
    "        smoothed_fsts=signal.medfilt(fsts, kernel_size = 101)\n",
    "\n",
    "        #add data to dataframe/table\n",
    "        data = list(zip([chrom]*len(fsts), chr_poss, fsts, smoothed_fsts, fst_calc_windows, fst_counts))\n",
    "        chr_df=pd.DataFrame(data, columns=headers)\n",
    "        df = df.append(chr_df)\n",
    "\n",
    "    #add cumul positions\n",
    "    fig_x_pos_s=[]\n",
    "    for index, row in df.iterrows(): \n",
    "        fig_x_pos_s.append(int(row[\"pos\"]) + int(cumul_start[row['chrom']]))\n",
    "\n",
    "    df['fig_x_pos']=fig_x_pos_s\n",
    "\n",
    "    #save data to csv file\n",
    "    csv_file = \"./results/fst_per_window/{}_vs_all_windowed_fst.csv\".format(pop)\n",
    "    df = df.sort_values([\"fig_x_pos\"], ascending = True)\n",
    "    df.to_csv(csv_file, index=False, header=True, mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
